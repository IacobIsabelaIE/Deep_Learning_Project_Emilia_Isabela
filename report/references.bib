@inproceedings{wang2019cnngenerated,
  title={CNN-generated images are surprisingly easy to spot...for now},
  author={Wang, Sheng-Yu and Wang, Oliver and Zhang, Richard and Owens, Andrew and Efros, Alexei A},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{ojha2023towards,
  author={Ojha, Utkarsh and Li, Yuheng and Lee, Yong Jae},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Towards Universal Fake Image Detectors that Generalize Across Generative Models}, 
  year={2023},
  pages={24480-24489},
  keywords={Training;Computer vision;Codes;Computational modeling;Buildings;Detectors;Generative adversarial networks;Image and video synthesis and generation},
  doi={10.1109/CVPR52729.2023.02345}
}

@inproceedings{zhu2023genimage,
 author={Zhu, Mingjian and Chen, Hanting and YAN, Qiangyu and Huang, Xudong and Lin, Guanyu and Li, Wei and Tu, Zhijun and Hu, Hailin and Hu, Jie and Wang, Yunhe},
 booktitle={Advances in Neural Information Processing Systems},
 pages={77771-77782},
 title={GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image},
 url={https://proceedings.neurips.cc/paper\_files/paper/2023/file/f4d4a021f9051a6c18183b059117e8b5-Paper-Datasets\_and\_Benchmarks.pdf},
 volume={36},
 year={2023}
}

@misc{midjourney,
  author = {Midjourney},
  url = {https://www.midjourney.com/home},
  year = {2022}
}

@misc{brock2019largescalegantraining,
      title={Large Scale GAN Training for High Fidelity Natural Image Synthesis}, 
      author={Andrew Brock and Jeff Donahue and Karen Simonyan},
      year={2019},
      eprint={1809.11096},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1809.11096}, 
}


@InProceedings{nichol2022glide,
  title = {{GLIDE}: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
  author = {Nichol, Alexander Quinn and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and Mcgrew, Bob and Sutskever, Ilya and Chen, Mark},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning},
  pages = {16784-16804},
  year = {2022},
  volume = {162},
  series = {Proceedings of Machine Learning Research},
  month = {17-23 Jul},
  publisher = {PMLR},
  pdf = {https://proceedings.mlr.press/v162/nichol22a/nichol22a.pdf},
  url = {https://proceedings.mlr.press/v162/nichol22a.html},
  abstract = {Diffusion models have recently been shown to generate high-quality synthetic images, especially when paired with a guidance technique to trade off diversity for fidelity. We explore diffusion models for the problem of text-conditional image synthesis and compare two different guidance strategies: CLIP guidance and classifier-free guidance. We find that the latter is preferred by human evaluators for both photorealism and caption similarity, and often produces photorealistic samples. Samples from a 3.5&nbsp;billion parameter text-conditional diffusion model using classifier-free guidance are favored by human evaluators to those from DALL-E, even when the latter uses expensive CLIP reranking. Additionally, we find that our models can be fine-tuned to perform image inpainting, enabling powerful text-driven image editing. We train a smaller model on a filtered dataset and release the code and weights at https://github.com/openai/glide-text2im.}
}

@inproceedings{dhariwal2021adm,
 author = {Dhariwal, Prafulla and Nichol, Alexander},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {8780-8794},
 title = {Diffusion Models Beat GANs on Image Synthesis},
 url = {https://proceedings.neurips.cc/paper\_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf},
 volume = {34},
 year = {2021}
}

@inproceedings{shuyang2022vqdm,
  author={Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Vector Quantized Diffusion Model for Text-to-Image Synthesis}, 
  year={2022},
  pages={10686-10696},
  keywords={Image quality;Computer vision;Image resolution;Image synthesis;Computational modeling;Noise reduction;Computer architecture;Image and video synthesis and generation; Vision + language},
  doi={10.1109/CVPR52688.2022.01043}
}

@inproceedings {robin2022sd,
author = { Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bjorn },
booktitle = { 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
title = {{ High-Resolution Image Synthesis with Latent Diffusion Models }},
year = {2022},
pages = {10674-10685},
keywords = {Training;Visualization;Image synthesis;Computational modeling;Noise reduction;Superresolution;Process control},
doi = {10.1109/CVPR52688.2022.01042},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR52688.2022.01042},
publisher = {IEEE Computer Society},
}

@inproceedings{francesco2019fingerprint,
  author={Marra, Francesco and Gragnaniello, Diego and Verdoliva, Luisa and Poggi, Giovanni},
  booktitle={2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)}, 
  title={Do GANs Leave Artificial Fingerprints?}, 
  year={2019},
  pages={506-511},
  doi={10.1109/MIPR.2019.00103}
}

@inproceedings{ning2019fingerprint,
  author={Yu, Ning and Davis, Larry and Fritz, Mario},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints}, 
  year={2019},
  pages={7555-7565},
  keywords={Gallium nitride;Generative adversarial networks;Visualization;Forensics;Training;Watermarking;Intellectual property},
  doi={10.1109/ICCV.2019.00765}
}

